---
title: "Project 1"
author: "William Buckey, Sidney Gehring, Micheal Purtle, Ruth Walters"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(ggplot2)
library(dplyr)
library(corrplot)
library(tidyr)
library(cowplot)
library(ggpubr)
library(GGally)
library(grid)
library(gridExtra)
library(MASS)
library(car)
library(boot)
library(caTools)
library(lmtest)
library(sandwich)
library(caret)
library(nlme)
library(betareg )

set.seed(123)

theme_set(theme_bw())
theme_update(
  plot.title = element_text(size = 12, face = "italic"), 
  axis.title.x = element_text(hjust = 0),
  axis.title.y = element_text(angle=90, hjust = 0, margin = margin(r = 5))
)
```

```{r plotting functions}
plot_four <- function(a, b, c, d, title) {
  plot_row <- plot_grid(a,b,c,d, align = "hv")
  
  title <- ggdraw() + 
    draw_label(title,
               fontface = 'bold',
               x = 0,
               hjust = 0) +
    theme(plot.margin = margin(0, 0, 0, 7))
  
  plot_grid(title, 
            plot_row,
            ncol = 1,
            rel_heights = c(0.1, 1))
}

plot_two <- function(a, b, title) {
  plot_row <- plot_grid(a,b, align = "hv")
  
  title <- ggdraw() + 
    draw_label(title,
               fontface = 'bold',
               x = 0,
               hjust = 0) +
    theme(plot.margin = margin(0, 0, 0, 7))
  
  plot_grid(title, 
            plot_row,
            ncol = 1,
            rel_heights = c(0.1, 1))
}
```

# Introduction

Economic mobility, or the ability of an individual to raise their economic status throughout their lifetime, is a marker of a healthy society. As economic mobility declines and income inequality rises throughout the United States, it is of increasing interest to determine which factors contribute to immobility. In this paper, we will investigate the correlation between economic, educational, and policy factors that contribute to economic mobility. We hypothesize that economic factors such as income inequality, will be most predictive of economic mobility, with higher levels of income disparity correlating with lower upward mobility.

# Exploratory data analysis

## Data cleaning and variable selection

```{r}
# Read in the mobility dataframe
mobility <- read.csv("mobility-all.csv", 
                     header = TRUE, 
                     stringsAsFactors = TRUE)
```

```{r view NAs}
# View NAs
nas <- colSums(is.na(mobility))
print(nas[nas > 0])
```


```{r clean data}
# Remove rows where a value for mobility is missing
mobilityTotalRows <- nrow(mobility)

mobility <- mobility %>%
  drop_na(Mobility) 

# Segment education-related variables
edu_mobility <- mobility[,(names(mobility) %in% c("Mobility", 
                                                   "School_spending", 
                                                   "Student_teacher_ratio", 
                                                   "Test_scores", 
                                                   "HS_dropout", 
                                                   "Colleges", 
                                                   "Tuition", 
                                                   "Graduation"))]

# Drop NAs
edu_mobility <- drop_na(edu_mobility)



# Remove qualitative variables
quals <- c("ID","Name", "State", "Latitude", "Longitude")
mobility <- mobility[,!(names(mobility) %in% quals)]

# Remove columns where more than 100 values are missing
bad_cols <- c("Colleges","Tuition", "Graduation", "HS_dropout") # +100 NULL
mobility <- mobility[,!(names(mobility) %in% bad_cols)]

# Drop remaining NA variables
mobility <- drop_na(mobility)

```

This dataset contains several rows for which one or more than one value is `NA`. Three steps were taken to eliminate `NA`s from the dataset while preserving its integrity.

1. *Drop the 12 rows that do not contain a value for `Mobility`* | These rows are useless for linear analysis because they do not contain the variable we are attempting to predict.

2. *Drop the features that contain a high incidence of `NA`s* | Any features that contained more than 100 NAs were designated as too poor in quality to be useful for the linear model. While some of these features were used for exploratory data analysis, they were removed from the dataset prior to modeling. 

3. *Drop all remaining `NA` values* | After removing the most `NA` values, a small amount of rows with `NA`s remained. These rows were dropped. 


Simply dropping all rows with `NA`s would have resulted in a reduction of `r (1 - (nrow(edu_mobility) / mobilityTotalRows)) * 100`% of the data whereas our three-step procedure only resulted in a reduction of `r (1 - (nrow(mobility) / mobilityTotalRows)) * 100`%.


Additionally, qualitative (non-numeric and non-quantitative) variables such as those representing latitude and longitude, state/region names, and the ID tag, were removed. 

## Education analysis

One of the principal research questions concerns whether better education can predict higher levels of economic mobility. The selected educational variables include School_spending (which is also discussed as a policy variable), Student-teacher_ratio, Test_scores, HS_dropout, Colleges, Tuition, and Graduation. These variables represent key aspects of the education system, including funding, resource allocation, academic performance, and attainment levels, and are critical in assessing educational impact. Since many of the features with the most missing values were related to education, a new data set was created of just the educational factors where all rows with NA values were dropped. 

```{r education analysis}
# Plot dropout rates distribution
p1 <- ggplot(edu_mobility, aes(x= HS_dropout)) + 
  geom_histogram(bins = 30, fill = 'dodgerblue', color = "black") + 
  ggtitle("HS Dropout Distribution") +
  xlab("High school dropout rate") +
  ylab("Frequency")

p2 <- ggplot(edu_mobility, aes(x = HS_dropout, y= Mobility)) + 
  geom_point(color = "dodgerblue", alpha = .3)  + 
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=.025, label.y=.3) +
  ggtitle("HS Dropout vs Mobility") + 
  xlab("High school dropout rate") +
  ylab("Mobility")

# Plot test score distribution
p3 <- ggplot(edu_mobility, aes(x= Test_scores)) + 
  geom_histogram(bins = 30, fill = 'tomato', color = "black") + 
  ggtitle("Test Scores Distribution")+
  xlab("Test scores") +
  ylab("Frequency") 

p4 <- ggplot(edu_mobility, aes(x = Test_scores, y= Mobility)) + 
  geom_point(color = "tomato", alpha = .3)  + 
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=-20, label.y=.3) +
  ggtitle("Test Scores vs Mobility")+
  xlab("Test scores") +
  ylab("Mobility")

# Plot student teacher ratio distribution
p5 <- ggplot(edu_mobility, aes(x= Student_teacher_ratio)) + 
  geom_histogram(bins = 30, fill = 'mediumseagreen', color = "black") + 
  ggtitle("Student Teacher Ratio Distribution") +
  xlab("Student-teacher ratio") +
  ylab("Frequency") 

p6 <- ggplot(edu_mobility, aes(x = Student_teacher_ratio, y= Mobility)) + 
  geom_point(color = "mediumseagreen", alpha = .3)  + 
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=18, label.y=.3) +
  ggtitle("Student Teacher Ratio vs Mobility") +
  xlab("Student-teacher ratio") +
  ylab("Mobility")

plot_row <- plot_grid(p1,p2,p3,p4,p5,p6,
                      align = "hv",
                      nrow = 3, 
                      ncol = 2)

title <- ggdraw() + 
  draw_label("Educational predictors of mobility",
             fontface = 'bold',
             x = 0,
             hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))

plot_grid(title, 
          plot_row,
          ncol = 1,
          rel_heights = c(0.1, 1))
```
The initial step involved creating a correlation plot using pairwise relationships between social variables (see Appendix A.1). This analysis identified the top two predictive variables: test_scores, with a correlation of 0.54, and HS_dropout, with a correlation of -0.44. Student_teacher_ratio and colleges exhibited some correlation with mobility, whereas Tuition and Graduation showed little to no correlation.

To further analyze the most strongly correlated variable, the distribution of test_scores was examined. The data followed a bell curve with a slight left skew. A scatter plot of mobility and Test_scores revealed a positive linear relationship with some variation. To quantify this variation, the standard deviation was calculated as 7.43, aligning with the observed distribution. A similar analysis was conducted for HS_dropout. The distribution displayed a right skew, and the scatter plot indicated a negative linear relationship, consistent with the correlation value.

## Policy analysis

By a similar procedure as above, three highly correlated variables related to government policy were identified:

1.	Local tax rate | Fraction of all income going to local taxes
2.	School expenditures | Average spending per pupil in public schools
3.	Local government spending | Local government spending per capita

Further, while there were other variables such as Chinese_imports and Manufacturing that were considered inclusion in this category, both features were deemed to stem both from business practices and general economic state along with government policy, complicating analysis. On the other hand, variables like local tax rate and school spending are dependent on how the government chooses to raise and spend funds.

Government policy is first examined by identifying the relationship between the three variables that are selected as predictors and verifying that these variables have a positive correlation between themselves. To verify these relations, a correlation matrix was created using pairwise relations (see Appendix A.2). We highlight the policy-associated variables and display the top 5 variables that are correlated with each (also Appendix A.2).

School_spending, Local_tax_rate, and Local_gov_spending all have a similar steady correlation with each other, verifying the covariant reliance on government policy. The sample variables are then used to generate a relationship scatter plot between each specific predicting variable using scatterplots. A linear regression line and R & p values are displayed to examine any trend lines. Further analysis of the relationship between school spending, local tax rates, and local government spending and demographic factors like income inequality can be found in Appendix B. 

```{r}
# Make a correlation matrix
cor_matrix <- cor(mobility, use = "pairwise.complete.obs")

# Pass the correlation matrix to a dataframe
cor_df <- as.data.frame(as.table(cor_matrix))
```


```{r}
# Remove diagonal correlations
cor_df <- cor_df %>%
  filter(Var1 != Var2)

# Standardize Var1 & Var2
cor_df <- cor_df %>%
  dplyr::rowwise() %>%
  dplyr::mutate(pair = paste(sort(c(Var1, Var2)), collapse = "_")) %>%
  dplyr::distinct(pair, .keep_all = TRUE) %>%
  dplyr::select(-pair)

# Sort by correlation
top_corr <- cor_df %>%
  arrange(desc(abs(Freq))) %>%  
  head(50)

# Define policy-driven variables
policy_vars <- c("Local_tax_rate", "Local_gov_spending", "Progressivity", "Gini", 
                 "School_spending", "Gini_99", "Test_scores", 
                 "HS_dropout", "Middle_class", "Social_capital", 
                 "Colleges", "Tuition", "Single_mothers")

# Correlation matrix
cor_matrix <- cor(mobility, use = "pairwise.complete.obs")

# Convert matrix into a dataframe
cor_df <- as.data.frame(as.table(cor_matrix))

# Remove diagonal correlations
cor_df <- cor_df %>%
  filter(Var1 != Var2)

# Standardize Var1 & Var2
cor_df <- cor_df %>%
  dplyr::rowwise() %>%
  dplyr::mutate(pair = paste(sort(c(Var1, Var2)), collapse = "_")) %>%  
  dplyr::distinct(pair, .keep_all = TRUE) %>%
  dplyr::select(-pair) 

# Find top 5 correlated variables
top_correlations <- list()

for (var in policy_vars) {
  top_5 <- cor_df %>%
    filter(Var1 == var | Var2 == var) %>% 
    arrange(desc(abs(Freq))) %>% 
    head(5)  
  top_correlations[[var]] <- top_5
}
```


```{r}
a <- ggplot(mobility, aes(x= School_spending)) + 
  geom_histogram(bins = 30, fill = 'mediumseagreen', color = "black") + 
  ggtitle("School Spending Distribution") +
  xlab("School spending ($)") +
  ylab("Frequency") + 
  scale_x_continuous(labels = scales::dollar_format())

b <- ggplot(mobility, aes(x = School_spending, y= Mobility)) + 
  geom_point(color = "mediumseagreen", alpha = .3)  + 
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=7.5, label.y=.3) +
  ggtitle("School spending vs mobility") +
  xlab("School spending ($)") + 
  ylab("Mobility") + 
  scale_x_continuous(labels = scales::dollar_format())

c <- ggplot(mobility, aes(x= Local_tax_rate)) + 
  geom_histogram(bins = 30, fill = 'dodgerblue', color = "black") + 
  ggtitle("Local tax rate distribution") +
  xlab("Local tax rate") +
  ylab("Frequency")

d <- ggplot(mobility, aes(x = Local_tax_rate, y= Mobility)) + 
  geom_point(color = "dodgerblue", alpha = .3)  + 
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=.04, label.y=.3) +
  ggtitle("Local tax rate vs mobility") +
  xlab("Local tax rate") + 
  ylab("Mobility")

e <- ggplot(mobility, aes(x= Local_gov_spending)) + 
  geom_histogram(bins = 30, fill = 'tomato', color = "black") + 
  ggtitle("Local government spending distribution") +
  xlab("Local government spending ($)") +
  ylab("Frequency") +
  scale_x_continuous(labels = scales::dollar_format())

f <- ggplot(mobility, aes(x = Local_gov_spending, y= Mobility)) + 
  geom_point(color = "tomato", alpha = .3)  + 
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=5000, label.y=.3) +
  ggtitle("Local government spending vs mobility") +
  xlab("Local government spending ($)") + 
  ylab("Mobility") + 
  scale_x_continuous(labels = scales::dollar_format())

plot_row <- plot_grid(c,d,e,f,a,b, 
                      align = "hv",
                      nrow = 3, 
                      ncol = 2)

title <- ggdraw() + 
  draw_label("Policy predictors of mobility",
             fontface = 'bold',
             x = 0,
             hjust = 0) +
  theme(plot.margin = margin(0, 0, 0, 7))

plot_grid(title, 
          plot_row,
          ncol = 1,
          rel_heights = c(0.1, 1))
```
These results state to us that while there might be outlier data in all 3 relational graphs, there still shows to be somewhat of a linear relationship between Mobility and Tax rate. This is interesting because school_spending had a higher relationship with demographic factors. School_spending and local_gov_spending do not seem to show as strong of a linear trend, but since School_spending had a high relationship with other demographic factors, I still will use it in my model.

## Segregation factors

Covariate analysis of segregation factors (`Seg_racial`, `Seg_poverty`, `Seg_affluence` and `Seg_income`- see **Appendix B.4**) indicated that, while segregation on poverty lines is not particularly well correlated with segregation on racial lines, it is highly associated with segregation by affluence and segregation by income, which are also highly associated with each other. Since `Seg_poverty`, `Seg_affluence` and `Seg_income` are so strongly co-linear, `Seg_affluence` and `Seg_income` will be removed from the model. 

Additionally, other income related factors that are generally associated with integration were examined (see **Appendix B.3**). The `Middle_class` variable is colinear with `Gini` and `Gini_99`, while the `Share01` variable is co-linear with `Gini`. Additionally, `Gini` seems to be highly predictive of `Gini_99`. `Income` is not strongly associated with any of the other variables examined. 

### Social determinants of mobility

```{r warning=FALSE}
a <- ggplot(mobility, aes(x= Seg_racial)) + 
  geom_histogram(bins = 30, fill = 'dodgerblue', color = "gray30") + 
  ggtitle("Distribution of segregation by race")+
  xlab("Segregation by race") +
  ylab("Frequency")

b <- ggplot(data = mobility, aes(x = Mobility, y = Seg_racial)) + 
  geom_point(color = "dodgerblue", alpha = .3) + 
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=.17, label.y=.5) +
  ylim(0,.6) + 
  ggtitle("Segregation by race vs mobility") +
  xlab("Mobility") + 
  ylab("Racial segregation")

c <- ggplot(mobility, aes(x= Seg_poverty)) + 
  geom_histogram(bins = 30, fill = 'tomato', color = "gray30") + 
  ggtitle("Distribution of segregation by poverty")+
  xlab("Segregation by poverty") +
  ylab("Frequency") 

d <- ggplot(data = mobility, aes(x = Mobility, y = Seg_poverty)) + 
  geom_point(color = "tomato", alpha = .3) +
  stat_smooth(method = "lm", formula = y ~ x, geom = "line", color = "black", se = FALSE) +
  stat_cor(label.x=.17, label.y=.15) +
  ylim(0,.17) +
  ggtitle("Segregation by poverty v mobility") + 
  xlab("Mobility") + 
  ylab("Poverty segregation")

plot_four(a,c,b,d, title = "Segregation as a predictor of mobility")
```

# Modeling

In our analysis of the factors associated with mobility, we employed both exploratory data analysis (EDA) and a multiple linear regression model, and a beta regression model to determine which variables exhibit a strong relationship with our outcome measure. Based on the regression output and correlation values from our EDA, we identified a subset of variables that appear particularly influential in explaining mobility.

## Linear model

```{r echo = TRUE}
lm.1 <- lm(formula = Mobility ~ ., 
   data = mobility)

c1 <- summary(lm.1)
```

From the first model built (see Appendix C.1 for output), iSchool_spending and Local_tax_rate do not have statistical evidence to prove an effect on economic mobility. However, another model was made to solely focus on the effects of government policy on mobility position. This model calls the 3 predicting government policy variables, as well as the sample demographic variables used earlier. These variables are grouped and fitted into a regression formula. From here, the formula is fitted, and the initial summary is complete. From the full model, it is already shown that the p value for Local_gov_spending was 0.225, which indicates that it not statistically significant for predicting mobility. The variables that proved to be statistically significant were then moved to the next step.

1. **Educational Spending**
- *School Spending* | Higher per-pupil expenditures can signal greater investment in educational resources, facilities, and student  support programs, thereby fostering improved long-term mobility outcomes.
- *Test Scores* |  These serve as a proxy for overall educational quality and student achievement, and they often correlate positively with economic and social mobility.
- *Colleges* | The presence and density of colleges in an area can enhance the availability of higher education and skill development opportunities, contributing to upward mobility.

2. **Social and Demographic Factors**
- `Black` & `Seg_racial` | The proportion of Black residents and the degree of racial segregation in a community are crucial indicators, reflecting underlying social structures and potential barriers or pathways to mobility. Areas with higher racial segregation often experience limited socioeconomic opportunities.
- `Commute` | Longer or more prevalent commutes could signal broader labor markets or suburban sprawl. Where commutes are feasible, individuals may have access to a wider range of job opportunities.
- `Gini` | Income inequality is often inversely related to mobility; higher inequality can concentrate disadvantage and limit pathways for advancement.
- `Middle_class` & `Progressivity` | Communities with a robust middle class or more progressive tax structures may provide support systems (e.g., social services, quality infrastructure) that encourage upward mobility.
- `Manufacturing` | A heavy reliance on manufacturing might limit economic diversification; in many cases, deindustrialization or technological shifts in manufacturing can hinder long-term mobility prospects.
- `Migration_in` | Areas experiencing inbound migration may be more economically dynamic, suggesting better job prospects and growth, which in turn can improve mobility opportunities.
- `Religious` | Higher religiosity can be associated with stronger community networks or social support, potentially facilitating resource sharing and stability that foster mobility.
- `Violent_crime` | High crime rates often correspond to reduced social cohesion and economic investment, negatively affecting people’s prospects for advancement.
- `Single_mothers` & `Divorced` | Family structure measures can indicate economic vulnerability or instability, impacting children’s outcomes and the intergenerational transmission of opportunity.

3. **Government Spending**
- `Local_tax_rate`: The percentage of local taxes levied on residents and businesses. While higher rates can reduce disposable income, they can also fund public services that may boost economic mobility.
- `Local_gov_spending`: Reflects how much local authorities invest in public services, infrastructure, and community programs. Effective spending can expand opportunities and resources, potentially promoting upward mobility.

```{r}
edu_corval <- c("School_spending", "Test_scores", "Colleges") #for edu stuff
social_cor <- c("Black", "Seg_racial", "Commute", "Gini", "Middle_class", 
               "Progressivity", "Manufacturing", "Migration_in", "Religious", 
               "Violent_crime", "Single mothers", "Divorced") #social stuff
gov_spending_stuff <- c("Local_tax_rate", "Local_goc_spending")

high_cor <- mobility[, names(mobility) %in% c("Mobility",edu_corval, social_cor, gov_spending_stuff)]

```

From a methodological standpoint, these variables are significant predictors in our regression and/or showed string correlation in EDA phase. To refine this model, we plan to:

* Check for Multicollinearity using Variance Inflation Factors (VIFs) to ensure no subset of variables is overly redundant.
* Check for Heteroskedasticity see if any of the variable have varying variance
* How influential are outliers in the model and see if we need to remove them

```{r}
yikes <- lm(Mobility ~ ., data = high_cor)

par(mfrow = c(2, 2))
plot(yikes)
c2 <- summary(yikes)
```
A numerical summary can be found in Appendix C.2.

We fitted the model, now let look for co-linearity between the variables then we can decide on how to deal with them. 
```{r}
vif(yikes)
```
Since the above factors are around 1-3, which suggest that colinearity isn't a huge concern. The highest VIF score is the "Middle_class" (about 4.097), which is borderline but still not extremely high. It's something to keep an eye on, but not a immediate concern.
```{r}
coeftest(yikes, vcov = vcovHC(yikes, type = "HC3"))
```
The result is a more refined model of each predictors estimated coefficient, its standard error, the t-statistic (coefficient / standard error), and the associated p-value (See Appendix C.3 for output). In short, there are variables like Black, Seg_Racial, Middle_class, Progressivity, Manufacturing, Religious, Divorced, and Local_tax_rate show significant relationships while some of the others do not reach conventional significance thresholds. And we in fact use the more significant variables when choosing our next model below.

```{r}
yikes_refit <- lm(Mobility ~ Black + 
                    Seg_racial +
                    Middle_class + 
                    Progressivity + 
                    Manufacturing + 
                    Migration_in + 
                    Religious + 
                    Divorced + 
                    Local_tax_rate, 
                  data = high_cor)
# coeftest(yikes_refit, vcov = vcovHC(yikes_refit, type = "HC3"))
```

```{r}
c3 <- summary(yikes_refit)
```
Having refined our model to include only statistically significant variables, we can now delve deeper into the data by identifying influential observations. The Q-Q plot below helps us pinpoint these observations, highlighting points that deviate from the expected distribution. These deviations may indicate outliers or data points that have a disproportionate impact on the model's performance, warranting further investigation.
```{r}
par(mfrow = c(2, 2))
plot(yikes_refit )
```

After examining the diagnostic plots (Residuals vs. Fitted, Q-Q Plot, Scale-Location, and Residuals vs. Leverage), we identified observations 320, 325, 326, and others as potential outliers or influential points. These points appeared to deviate substantially from the overall trend, suggesting they might exert an undue influence on the regression results.

**Why Remove Outliers?**

1. *Influence on Parameter Estimates* | Outliers can disproportionately affect the estimated coefficients, leading to skewed interpretations.
2. *Violation of Model Assumptions* | If extreme points violate assumptions of normality or homoscedasticity, they can compromise the validity of the model’s inferences.
3. *Model Fit* | Removing influential points may improve the model fit and reveal a clearer relationship among the remaining data.

Now we just have to remove the outliers and refit the model.

```{r}
high_cor_clean <- high_cor[-c(320, 325, 326, 385, 391, 393), ]
yikes_clean <- lm(Mobility ~ Black + Seg_racial + Middle_class + Progressivity + Manufacturing + Migration_in + Religious + Divorced + Local_tax_rate, data = high_cor_clean)

c4 <- summary(yikes_clean)

par(mfrow = c(2, 2))
plot(yikes_clean)

```


This is likely the best we can achieve using a simple linear regression model, given that we’re attempting to predict a probability (mobility). Because probabilities are bounded between 0 and 1, linear regression can struggle to provide accurate predictions or valid inferences in this context. As a result, we may need a more advanced modeling technique—such as logistic regression or another specialized method—to capture the probabilistic nature of mobility. This modeling mismatch is probably why we’ve encountered multiple issues when trying to predict mobility with a simple linear approach.

## Beta regression

For the next model, I plan to use beta regression because it is specifically designed for response variables that lie between 0 and 1. However, before proceeding with beta regression, we need to verify that all values of our response variable lie strictly within the (0, 1) interval—a key assumption for beta regression.

We can confirm this in R with the following code:

```{r echo = TRUE}
all(high_cor$Mobility > 0 & high_cor$Mobility < 1)
```

If this returns TRUE, it confirms that all values meet the (0, 1) requirement, and we can confidently move forward with the beta regression analysis.

While the histogram does not provide sufficient evidence that mobility follows a beta distribution, we can use the Kolmogorov-Smirnov (K-S), which essentially asks: ‘How likely is it that we would observe these two samples if they were drawn from the same probability distribution?’

```{r}
# Fit beta distribution parameters
mobility_fit <- fitdistr(high_cor$Mobility, "beta", start = list(shape1 = 2, shape2 = 5))

# Generate theoretical beta values
x_vals <- seq(min(high_cor$Mobility), max(high_cor$Mobility), length.out = 100)
beta_vals <- dbeta(x_vals, mobility_fit$estimate[1], mobility_fit$estimate[2])

# Plot the histogram and beta density curve
hist(high_cor$Mobility, breaks = 30, 
     probability = TRUE, 
     col = "dodgerblue", 
     main = "Fit of Beta Distribution",
     xlab = "Mobility")
lines(x_vals, beta_vals, col = "red", lwd = 2)


ks.test(high_cor$Mobility, "pbeta", mobility_fit$estimate[1], mobility_fit$estimate[2])

```

The p-value from the one-sample Kolmogorov-Smirnov test is 0.05856, which is slightly above the conventional 0.05 threshold. This suggests that we do not have strong evidence to reject the null hypothesis that our data follow a beta distribution.

Beta regression
```{r}
yikes_beta <- betareg(Mobility ~ Black + Seg_racial + Middle_class + Progressivity + Manufacturing + Migration_in + Religious + Divorced + Local_tax_rate, 
                      data = high_cor)
c5 <- summary(yikes_beta)
par(mfrow = c(2, 2))
plot(yikes_beta)
```

Overall, the beta regression model appears to be performing well based on several diagnostic indicators. First, the significance of the predictors in the mean model is high, with all coefficients (except Migration_in, which is still below the 0.05 threshold) showing very low p-values. This suggests that each variable contributes meaningfully to explaining the variability in Mobility. Furthermore, the pseudo R-squared value of approximately 0.75 indicates that the model accounts for a substantial portion of the variation in the data—quite high for a beta regression.

Looking at the diagnostic plots, the residuals versus observation indices and the residuals versus the linear predictor do not exhibit strong patterns, suggesting no obvious violations of model assumptions. The Cook’s distance plot reveals that no single observation exerts undue influence on the model, and generalized leverage values are mostly low, indicating limited leverage points. Lastly, the estimated precision $\phi \approx 150$ is relatively large, pointing to a tightly clustered distribution around the fitted values. Taken together, these diagnostics imply that the beta regression model is a good fit, although you may want to confirm its predictive performance through additional fit metrics or cross-validation.


```{r}
model_aic <- AIC(yikes_beta)
model_bic <- BIC(yikes_beta)

cat("AIC:", model_aic, "\n")
cat("BIC:", model_bic, "\n")

set.seed(123)

n_folds <- 5


folds <- sample(1:n_folds, size = nrow(high_cor), replace = TRUE)


rmse_vals <- numeric(n_folds)

for (k in 1:n_folds) {
  

  train_idx <- which(folds != k)
  test_idx  <- which(folds == k)
  

  fit_k <- betareg(
    Mobility ~ Black + Seg_racial + Middle_class + Progressivity + 
      Manufacturing + Migration_in + Religious + Divorced,
    data = high_cor[train_idx, ]
  )
  

  preds <- predict(fit_k, newdata = high_cor[test_idx, ], type = "response")
  actuals <- high_cor$Mobility[test_idx]
  

  rmse_vals[k] <- sqrt(mean((preds - actuals)^2))
}


mean_rmse <- mean(rmse_vals)

cat("Mean RMSE (5-fold CV):", mean_rmse, "\n")
```

The model's fit is strong, as indicated by the AIC (-2972.293) and BIC (-2923.338), which suggest excellent in-sample fit, with lower values signifying a better model. The mean RMSE from the 5-fold cross-validation is 0.0276, meaning that, on average, the model's predictions are off by just 2.8 percentage points—indicating good predictive accuracy. Overall, these results suggest that your beta regression model is well-calibrated, performing well both in terms of fit and prediction. However, comparing these metrics across different models can provide additional insights into the relative performance. 

The negative AIC and BIC values indicate that the model has a high likelihood relative to its complexity, though these measures are most informative when comparing across multiple models. Meanwhile, the mean RMSE of approximately 0.028 suggests that, on average, the model’s predictions deviate from the actual values by about 2.8 percentage points on the 0–1 scale, which is fairly small. Taken together, these results suggest that the beta regression model fits the data well, although further comparisons with alternative models or additional diagnostics would provide a more comprehensive assessment.

# Appendices

## Appendix A

### A.1   Education covariate analysis

```{r}
cor_matrix <- cor(edu_mobility, use = "pairwise.complete.obs") 
corrplot(cor_matrix, 
         method = "color",
         type = "upper",
         col = colorRampPalette(c("tomato", "white", "dodgerblue"))(200),
         tl.cex = 0.6, 
         number.cex = 0.8,
         addCoef.col = "black",
         tl.col = "black",
         tl.srt = 30)
```

### A.2 	Policy covariate analysis

```{r}
# Make a heatmap
corrplot(cor_matrix,
         method = "color",  
         tl.col = "black",  
         tl.cex = 0.5, 
         tl.srt = 45,
         col = colorRampPalette(c("tomato", "white", "dodgerblue"))(200))
```

```{r}
# Print strongest correlations
print("School spending: ") 
print(top_correlations$School_spending)
print("Local tax rate: ")
print(top_correlations$Local_tax_rate)
print("Local government spending: ")
print(top_correlations$Local_gov_spending)
```

```{r}
mobility[c("Seg_poverty", "Seg_racial", "Seg_affluence", "Seg_income")] %>%
  ggpairs(aes(alpha = 0.5), 
          upper = list(continuous = wrap("cor", size = 5)),
          columnLabels = c("Poverty", "Race", "Affluence", "Income"),
          title = "Colinearity analysis of segregation",
          progress = FALSE)
```

### A.3 Segregation covariate analysis

```{r}
mobility[c("Middle_class", "Income", "Gini", "Gini_99", "Share01")] %>%
  ggpairs(aes(alpha = 0.5), 
          upper = list(continuous = wrap("cor", size = 5)),
          columnLabels = c("Middle class", "Income", "Gini index", "Adj. Gini", "Share01"),
          title = "Colinearity analysis of income and income inequality",
          progress = FALSE)
```

## Appendix B

```{r message=FALSE, warning=FALSE}
# Create scatter plots
plot_scatter <- function(x_var, color, text_size = 5, r_p_size = 5, keep_axis_titles = FALSE) {  
  ggplot(mobility, aes(.data[[x_var]], School_spending)) +  
    geom_point(color = color, alpha = .3) + 
    geom_smooth(method = "lm", color = "black", se = FALSE) +  # Add linear regression line
    stat_cor(label.x = min(mobility[[x_var]], na.rm = TRUE), 
             label.y = max(mobility$School_spending, na.rm = TRUE) * 0.9, 
             size = r_p_size) +  # Adds R & p-values 
    ggtitle(paste(x_var)) + 
    theme_minimal() +
    theme(
      axis.title = if (keep_axis_titles) element_text(size = 10) else element_blank(),  
      axis.text = element_text(size = 8),  
      plot.title = element_text(hjust = 0.5, size = 10) 
    )
}

# Create plots for other variables 
p1 <- plot_scatter("Seg_poverty", "mediumseagreen", r_p_size = 2)
p2 <- plot_scatter("Gini", "mediumseagreen", r_p_size = 2)
p3 <- plot_scatter("Gini_99", "mediumseagreen", r_p_size = 2)
p4 <- plot_scatter("Middle_class", "mediumseagreen", r_p_size = 2)
p5 <- plot_scatter("Single_mothers", "mediumseagreen", r_p_size = 2)
p6 <- plot_scatter("Test_scores", "mediumseagreen", r_p_size = 2)

# Display all other plots on one page
grid.arrange(
  arrangeGrob(p1, p2, p3, p4, p5, p6, ncol = 2, 
              top = textGrob("Demographic Variables vs School Spending", 
                             gp = gpar(fontsize = 10, fontface = "bold")))
)
```

```{r, message=FALSE, warning=FALSE}
data <- mobility

# Create scatter plots
plot_scatter <- function(x_var, color, text_size = 5, r_p_size = 5, keep_axis_titles = FALSE) {  
  ggplot(data, aes(.data[[x_var]], Local_tax_rate)) + 
    geom_point(color = color, alpha = .3) + 
    geom_smooth(method = "lm", color = "black", se = FALSE) +  
    stat_cor(label.x = min(data[[x_var]]), 
             label.y = max(data$Local_tax_rate, na.rm = TRUE) * 0.9, 
             size = r_p_size) + 
    ggtitle(paste(x_var)) + 
    theme_minimal() +
    theme(
      axis.title = if (keep_axis_titles) element_text(size = 10) else element_blank(), 
      axis.text = element_text(size = 8),  
      plot.title = element_text(hjust = 0.5, size = 10) 
    )
}

# Create plots for other variables 
p1 <- plot_scatter("Seg_poverty", "dodgerblue", r_p_size = 2)
p2 <- plot_scatter("Gini", "dodgerblue", r_p_size = 2)
p3 <- plot_scatter("Gini_99", "dodgerblue", r_p_size = 2)
p4 <- plot_scatter("Middle_class", "dodgerblue", r_p_size = 2)
p5 <- plot_scatter("Single_mothers", "dodgerblue", r_p_size = 2)
p6 <- plot_scatter("Test_scores", "dodgerblue", r_p_size = 2)

# Arrange and display all other plots on one page 
grid.arrange(
  arrangeGrob(p1, p2, p3, p4, p5, p6, ncol = 2,  
              top = textGrob("Demographic Variables vs Local Tax Rate", 
                             gp = gpar(fontsize = 10, fontface = "bold")))
)
```

```{r, message=FALSE, warning=FALSE}
# Create scatter plots
plot_scatter <- function(x_var, color, text_size = 5, r_p_size = 5, keep_axis_titles = FALSE) {  
  ggplot(data, aes(.data[[x_var]], Local_gov_spending)) +  
    geom_point(color = color, alpha = .3, na.rm = TRUE) + 
    geom_smooth(method = "lm", color = "black", se = FALSE) +  
    stat_cor(label.x = min(data[[x_var]], na.rm = TRUE), 
             label.y = max(data$Local_gov_spending, na.rm = TRUE) * 0.9, 
             size = r_p_size) + 
    ggtitle(paste(x_var)) +  
    theme_minimal() +
    theme(
      axis.title = if (keep_axis_titles) element_text(size = 10) else element_blank(),  
      axis.text = element_text(size = 8),  
      plot.title = element_text(hjust = 0.5, size = 10)  
    )
}

# Create plots for other variables 
p1 <- plot_scatter("Seg_poverty", "tomato", r_p_size = 2)
p2 <- plot_scatter("Gini", "tomato", r_p_size = 2)
p3 <- plot_scatter("Gini_99", "tomato", r_p_size = 2)
p4 <- plot_scatter("Middle_class", "tomato", r_p_size = 2)
p5 <- plot_scatter("Single_mothers", "tomato", r_p_size = 2)
p6 <- plot_scatter("Test_scores", "tomato", r_p_size = 2)


# Arrange and display all other plots on one page 
grid.arrange(
  arrangeGrob(p1, p2, p3, p4, p5, p6, ncol = 2,  
              top = textGrob("Demographic Variables vs Local Government Spending", 
                             gp = gpar(fontsize = 10, fontface = "bold")))
)

```

## Appendix C

### C.1 	Initial linear modeling output

```{r}
print(c1)
```

### C.2 	"High correlation" linear modeling output

```{r}
print(c2)
```


### C.3   Refined linear modeling output

```{r}
print(c3)
```


### C.4   Final linear modeling output

```{r}
print(c4)
```


### C.5   Beta regression results

```{r}
print(c5)
```
